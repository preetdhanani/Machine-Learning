{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEJSjM8RthIj"
   },
   "source": [
    "# Applied Machine Learning \n",
    "\n",
    "## Homework 4: Logistic regression, hyperparameter optimization \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTJi1SgKthIo"
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kptiUzhfthIp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slQGtk_UthIq"
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNMNABoEthIr"
   },
   "source": [
    "## Exercise 1: Implementing `DummyClassifier` \n",
    "<hr>\n",
    "rubric={points:25}\n",
    "\n",
    "In this course you will generally **not** be asked to implement machine learning algorihtms (like logistic regression) from scratch. However, this exercise is an exception: you will implement the simplest possible classifier, `DummyClassifier`.\n",
    "\n",
    "As a reminder, `DummyClassifier` is meant as a baseline and is generally the worst possible \"model\" you could \"fit\" to a dataset. All it does is predict the most popular class in the training set. So if there are more 0s than 1s it predicts 0 every time, and if there are more 1s than 0s it predicts 1 every time. For `predict_proba` it looks at the frequencies in the training set, so if you have 30% 0's 70% 1's it predicts `[0.3 0.7]` every time. Thus, `fit` only looks at `y` (not `X`).\n",
    "\n",
    "Below you will find starter code for a class called `MyDummyClassifier`, which has methods `fit()`, `predict()`, `predict_proba()` and `score()`. Your task is to fill in those four functions. To get your started, I have given you a `return` statement in each case that returns the correct data type: `fit` can return nothing, `predict` returns an array whose size is the number of examples, `predict_proba` returns an array whose size is the number of examples x 2, and `score` returns a number.\n",
    "\n",
    "The next code block has some tests you can use to assess whether your code is working. \n",
    "\n",
    "I suggest starting with `fit` and `predict`, and making sure those are working before moving on to `predict_proba`. For `predict_proba`, you should return the frequency of each class in the training data, which is the behaviour of `DummyClassifier(strategy='prior')`. Your `score` function should call your `predict` function. Again, you can compare with `DummyClassifier` using the code below.\n",
    "\n",
    "To simplify this question, you can assume **binary classification**, and furthermore that these classes are **encoded as 0 and 1**. In other words, you can assume that `y` contains only 0s and 1s. The real `DummyClassifier` works when you have more than two classes, and also works if the target values are encoded differently, for example as \"cat\", \"dog\", \"mouse\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kOdJ-JEEthIs"
   },
   "outputs": [],
   "source": [
    "class MyDummyClassifier:\n",
    "    \"\"\"\n",
    "    A baseline classifier that predicts the most common class.\n",
    "    The predicted probabilities come from the relative frequencies\n",
    "    of the classes in the training data.\n",
    "\n",
    "    This implementation only works when y only contains 0s and 1s.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.prob = pd.DataFrame(y).value_counts(normalize=True).values\n",
    "        self.classs = pd.DataFrame(y).value_counts().idxmax()\n",
    "        self.cls = pd.DataFrame(y).value_counts().idxmax()\n",
    "        return None # Replace with your code\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        return np.full(X.shape[0],self.classs)  # Replace with your code\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        print(np.full((X.shape[0], 2),self.prob))\n",
    "        return np.full((X.shape[0], 2),self.prob)  # Replace with your code\n",
    "\n",
    "    def score(self, X, y):\n",
    "        score1 = pd.DataFrame(y).value_counts().loc[self.cls]/len(y)\n",
    "        \n",
    "        return score1  # Replace with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6o9lTGRothIs"
   },
   "source": [
    "Below are some tests for `predict` using randomly generated data. You may want to run the cell a few times to make sure you explore the different cases (or automate this with a loop or random seeds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aBbDx10AthIt"
   },
   "outputs": [],
   "source": [
    "# For testing, generate random data\n",
    "n_train = 101\n",
    "n_valid = 21\n",
    "d = 5\n",
    "X_train_dummy = np.random.randn(n_train, d)\n",
    "X_valid_dummy = np.random.randn(n_valid, d)\n",
    "y_train_dummy = np.random.randint(2, size=n_train)\n",
    "y_valid_dummy = np.random.randint(2, size=n_valid)\n",
    "\n",
    "my_dc = MyDummyClassifier()\n",
    "sk_dc = DummyClassifier(strategy=\"prior\")\n",
    "\n",
    "sk_dc.fit(X_train_dummy, y_train_dummy)\n",
    "my_dc.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "assert np.array_equal(my_dc.predict(X_train_dummy), sk_dc.predict(X_train_dummy))\n",
    "assert np.array_equal(my_dc.predict(X_valid_dummy), sk_dc.predict(X_valid_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjPR99BtthIu"
   },
   "source": [
    "Below are some tests for `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XrKgHtRLthIu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]\n",
      " [0.52475248 0.47524752]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[0;32m      2\u001b[0m     my_dc\u001b[38;5;241m.\u001b[39mpredict_proba(X_train_dummy), sk_dc\u001b[38;5;241m.\u001b[39mpredict_proba(X_train_dummy)\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[0;32m      5\u001b[0m     my_dc\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid_dummy), sk_dc\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid_dummy)\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(\n",
    "    my_dc.predict_proba(X_train_dummy), sk_dc.predict_proba(X_train_dummy)\n",
    ")\n",
    "assert np.allclose(\n",
    "    my_dc.predict_proba(X_valid_dummy), sk_dc.predict_proba(X_valid_dummy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8x2RV4nthIu"
   },
   "source": [
    "Below are some tests for `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COFJXNygthIv"
   },
   "outputs": [],
   "source": [
    "assert np.isclose(\n",
    "    my_dc.score(X_train_dummy, y_train_dummy), sk_dc.score(X_train_dummy, y_train_dummy)\n",
    ")\n",
    "assert np.isclose(\n",
    "    my_dc.score(X_valid_dummy, y_valid_dummy), sk_dc.score(X_valid_dummy, y_valid_dummy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNFMYiBxthIv"
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQCBwZ_cthIv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e3cc53df86a7e14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 2: Trump Tweets\n",
    "<hr>\n",
    "\n",
    "For the rest of this assignment we'll be looking at a [dataset of Donald Trump's tweets](https://www.kaggle.com/austinreese/trump-tweets) as of June 2020. You should start by downloading the dataset. Unzip it and move the file `realdonaldtrump.csv` into this directory. As usual, please do not submit the dataset when you submit the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rk16lFx8vhsf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1698308935</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701461182</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737479987</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741160716</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773561338</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         link  \\\n",
       "id                                                              \n",
       "1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
       "1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
       "1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
       "1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
       "\n",
       "                                                      content  \\\n",
       "id                                                              \n",
       "1698308935  Be sure to tune in and watch Donald Trump on L...   \n",
       "1701461182  Donald Trump will be appearing on The View tom...   \n",
       "1737479987  Donald Trump reads Top Ten Financial Tips on L...   \n",
       "1741160716  New Blog Post: Celebrity Apprentice Finale and...   \n",
       "1773561338  \"My persona will never be that of a wallflower...   \n",
       "\n",
       "                           date  retweets  favorites mentions hashtags  \n",
       "id                                                                      \n",
       "1698308935  2009-05-04 13:54:25       510        917      NaN      NaN  \n",
       "1701461182  2009-05-04 20:00:10        34        267      NaN      NaN  \n",
       "1737479987  2009-05-08 08:38:08        13         19      NaN      NaN  \n",
       "1741160716  2009-05-08 15:40:15        11         26      NaN      NaN  \n",
       "1773561338  2009-05-12 09:07:28      1375       1945      NaN      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"realdonaldtrump.csv\", index_col=0)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pUW5zveoviU-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43352, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTfjUruYthIw"
   },
   "source": [
    "We will be trying to predict whether a tweet will go \"viral\", defined as having more than 10,000 retweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "--B-sK6hvkJG"
   },
   "outputs": [],
   "source": [
    "y = tweets_df[\"retweets\"] > 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gm_TwM7thIx"
   },
   "source": [
    "To make predictions, we'll be using only the content (text) of the tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lWLE1kiQvoWW"
   },
   "outputs": [],
   "source": [
    "X=tweets_df[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1698308935             Be sure to tune in and watch Donald Trump on L...\n",
       "1701461182             Donald Trump will be appearing on The View tom...\n",
       "1737479987             Donald Trump reads Top Ten Financial Tips on L...\n",
       "1741160716             New Blog Post: Celebrity Apprentice Finale and...\n",
       "1773561338             \"My persona will never be that of a wallflower...\n",
       "                                             ...                        \n",
       "1273405198698975232    Joe Biden was a TOTAL FAILURE in Government. H...\n",
       "1273408026968457216    Will be interviewed on @ seanhannity tonight a...\n",
       "1273442195161387008                           pic.twitter.com/3lm1spbU8X\n",
       "1273442469066276864                           pic.twitter.com/vpCE5MadUz\n",
       "1273442528411385858                           pic.twitter.com/VLlc0BHW41\n",
       "Name: content, Length: 43352, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY0PMVmYthIx"
   },
   "source": [
    "For the purpose of this assignment, you can ignore all the other columns in the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNs-kQkEthIx"
   },
   "source": [
    "#### 2(a) ordering the steps\n",
    "rubric={points:8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiMXWxzDthIx"
   },
   "source": [
    "Let's start by building a model using `CountVectorizer` and `LogisticRegression`. The code required to do this has been provided below, but in the wrong order. \n",
    "\n",
    "- Rearrange the lines of code to correctly fit the model and compute the cross-validation score. \n",
    "- Add a short comment to each block to describe what the code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1698308935             False\n",
       "1701461182             False\n",
       "1737479987             False\n",
       "1741160716             False\n",
       "1773561338             False\n",
       "                       ...  \n",
       "1273405198698975232     True\n",
       "1273408026968457216     True\n",
       "1273442195161387008    False\n",
       "1273442469066276864    False\n",
       "1273442528411385858    False\n",
       "Name: retweets, Length: 43352, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_rDIBYEJthIy",
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       3.748299\n",
       "score_time     0.218735\n",
       "test_score     0.897890\n",
       "train_score    0.967045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR COMMENT HERE\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "pipe = make_pipeline(countvec, lr)\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=321)\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "cross_val_results = pd.DataFrame(\n",
    "    cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    ")\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "cross_val_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4cS6TCythIy"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHI7frmRthIy"
   },
   "source": [
    "#### 2(b) Cross-validation fold sub-scores\n",
    "rubric={points:5}\n",
    "\n",
    "Above we averaged the scores from the 5 folds of cross-validation. \n",
    "\n",
    "- Print out the 5 individual scores. Reminder: `sklearn` calls them `\"test_score\"` but they are really (cross-)validation scores. \n",
    "- Are the 5 scores close to each other or spread far apart? (This is a bit subjective, answer to the best of your ability.)\n",
    "- How does the size of this dataset (number of rows) compare to the cities dataset we have been using in class? How does this relate to the different sub-scores from the 5 folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.207818</td>\n",
       "      <td>0.218167</td>\n",
       "      <td>0.899123</td>\n",
       "      <td>0.966014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.028064</td>\n",
       "      <td>0.170868</td>\n",
       "      <td>0.899739</td>\n",
       "      <td>0.968859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.630826</td>\n",
       "      <td>0.230297</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>0.965976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.533470</td>\n",
       "      <td>0.177040</td>\n",
       "      <td>0.898201</td>\n",
       "      <td>0.968552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.252655</td>\n",
       "      <td>0.208355</td>\n",
       "      <td>0.896032</td>\n",
       "      <td>0.965823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  3.207818    0.218167    0.899123     0.966014\n",
       "1  3.028064    0.170868    0.899739     0.968859\n",
       "2  2.630826    0.230297    0.896356     0.965976\n",
       "3  2.533470    0.177040    0.898201     0.968552\n",
       "4  2.252655    0.208355    0.896032     0.965823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_results = pd.DataFrame(\n",
    "    cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    ")\n",
    "(cross_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all 5 are close to each other, reason is its not numerics,thus there are no bias data all are words, so shuffeling them is not good choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDmTPq0pthIz"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO8insKFthIz"
   },
   "source": [
    "#### 2(c) baseline\n",
    "rubric={points:3}\n",
    "\n",
    "By the way, are these scores any good? \n",
    "\n",
    "- Run `DummyClassifier` (or `MyDummyClassifier`!) on this dataset.\n",
    "- Compare the `DummyClassifier` score to what you got from logistic regression above. Does logistic regression seem to be doing anything useful?\n",
    "- Is it necessary to use `CountVectorizer` here? Briefly explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip2 =make_pipeline(countvec,DummyClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_results1 = pd.DataFrame(\n",
    "    cross_validate(pip2, X_train, y_train, return_train_score=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916372</td>\n",
       "      <td>0.218440</td>\n",
       "      <td>0.738582</td>\n",
       "      <td>0.738534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.897976</td>\n",
       "      <td>0.180898</td>\n",
       "      <td>0.738582</td>\n",
       "      <td>0.738534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866991</td>\n",
       "      <td>0.181721</td>\n",
       "      <td>0.738582</td>\n",
       "      <td>0.738534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906849</td>\n",
       "      <td>0.197701</td>\n",
       "      <td>0.738428</td>\n",
       "      <td>0.738572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.845925</td>\n",
       "      <td>0.216250</td>\n",
       "      <td>0.738542</td>\n",
       "      <td>0.738544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.916372    0.218440    0.738582     0.738534\n",
       "1  0.897976    0.180898    0.738582     0.738534\n",
       "2  0.866991    0.181721    0.738582     0.738534\n",
       "3  0.906849    0.197701    0.738428     0.738572\n",
       "4  0.845925    0.216250    0.738542     0.738544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgRKRF7fthIz"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlhwuMxZthIz"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B62t4N-thIz",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba1f8ea22638cf75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2(d) probability scores\n",
    "rubric={points:5}\n",
    "\n",
    "Here we train a logistic regression classifier on the entire training set: \n",
    "\n",
    "(Note: this is relying on the `pipe` variable from 2(a) - you'll need to redefine it if you overwrote that variable in between.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bkCXQCyKthI0"
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CjJfSRythI0"
   },
   "source": [
    "Using this model, find the tweet in the **test set** with the highest predicted probability of being viral. Print out the tweet and the associated probability score.\n",
    "\n",
    "Reminder: you are free to reuse/adapt code from lecture. Please add in a small attribution, e.g. \"From Lecture 7\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.68536669e-02, 9.73146333e-01],\n",
       "       [3.72687117e-04, 9.99627313e-01],\n",
       "       [5.64193182e-02, 9.43580682e-01],\n",
       "       ...,\n",
       "       [9.93701871e-01, 6.29812932e-03],\n",
       "       [9.58455633e-01, 4.15443674e-02],\n",
       "       [2.60189063e-05, 9.99973981e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pipe.predict_proba(X_test)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(x,columns=['False','True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5620\n",
       "True     5134\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.idxmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corrupt politician Adam Schiff wants people from the White House to testify in his and Pelosi’s disgraceful Witch Hunt, yet he will not allow a White House lawyer, nor will he allow ANY of our requested witnesses. This is a first in due process and Congressional history!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[5134]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfYVY5C5thI0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFirvlAnthI0"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHiHwL20thI0",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f910e9d1d6d09182",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2(e) coefficients\n",
    "rubric={points:4}\n",
    "\n",
    "We can extract the `CountVectorizer` and `LogisticRegression` objects from the `make_pipeline` object as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y-cPHigAthI1"
   },
   "outputs": [],
   "source": [
    "vec_from_pipe = pipe.named_steps[\"countvectorizer\"]\n",
    "lr_from_pipe = pipe.named_steps[\"logisticregression\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuKgKbbxthI1"
   },
   "source": [
    "Using these extracted components above, display the 5 words with the highest coefficients and the 5 words with the smallest coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "625116052440137728     Always great to speak with Veterans - our nati...\n",
       "709735250927226880     North Carolina lost 300,000 manufacturing jobs...\n",
       "693263187702059008     THANK YOU to all of the incredible volunteers,...\n",
       "338042150812012546     It should be mandatory that all haters and los...\n",
       "1265301249630654467    For all of the political hacks out there, if I...\n",
       "                                             ...                        \n",
       "661356183123591168     \" @ kemper34: @ TheHerd @ ColinCowherd @ realD...\n",
       "294551971610902528      “Don't find fault, find a remedy.” -- Henry Ford\n",
       "263691262819987456     . @ oreillyfactor called me a \"master marketee...\n",
       "304432499507994628                                 @ RobertSuppa. Thanks\n",
       "859143061678501892     # ICYMI- On Saturday I signed two EO's to help...\n",
       "Name: content, Length: 32514, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32514,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(lr_from_pipe.coef_.flatten(),columns=['coef']).sort_values(['coef'],ascending=False).head(5).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17729, 24999, 14919, 10915, 36825], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17729</th>\n",
       "      <td>harassment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14919</th>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36825</th>\n",
       "      <td>transcripts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "17729   harassment\n",
       "24999         mini\n",
       "14919         fake\n",
       "10915  coronavirus\n",
       "36825  transcripts"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vec_from_pipe.get_feature_names_out()).iloc[temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame(lr_from_pipe.coef_.flatten(),columns=['coef']).sort_values(['coef'],ascending=False).tail(5).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37051</th>\n",
       "      <td>trump2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>barackobama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37055</th>\n",
       "      <td>trump2016pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30315</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "2219              1pic\n",
       "37051        trump2016\n",
       "6928       barackobama\n",
       "37055     trump2016pic\n",
       "30315  realdonaldtrump"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vec_from_pipe.get_feature_names_out()).iloc[temp2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsnEgeRathI1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jgp9NsQthI1"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESEDNTiTthI1"
   },
   "source": [
    "#### 2(f)\n",
    "rubric={points:10}\n",
    "\n",
    "scikit-learn provides a lot of useful tools like `make_pipeline` and `cross_validate`, which are awesome. But with these fancy tools it's also easy to lose track of what is actually happening under the hood. Here, your task is to \"manually\" (without `Pipeline` and without `cross_validate` or `cross_val_score`) compute logistic regression's validation score on one fold (that is, train on 80% and validate on 20%) of the training data. \n",
    "\n",
    "You should start with the following `CountVectorizer` and `LogisticRegression` objects, as well as `X_train` and `y_train` (which you should further split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0q-ONzDdthI2"
   },
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "lr = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train,X_train_test,y_train_train,y_train_test = train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = countvec.fit_transform(X_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_test = countvec.transform(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(t2,y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9685133212871477"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.score(t2,y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962017530370598"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.score(t2_test,y_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qva4yjH2thI2"
   },
   "source": [
    "Meta-comment: you might be wondering why we're going into \"implementation\" here if this course is about _applied_ ML. In CPSC 340, we would go all the way down into `LogisticRegression` and understand how `fit` works, line by line. Here we're not going into that at all, but I still think this type of question (and Exercise 1) is a useful middle ground. I do want you to know what is going on in `Pipeline` and in `cross_validate` even if we don't cover the details of `fit`. To get into logistic regression's `fit` requires a bunch of math; here, we're keeping it more conceptual and avoiding all those prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whJW86BEthI3"
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-AJnpxTthI3",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 3: hyperparameter optimization\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUADN93QthI3",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e9e6fdea209d872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3(a)\n",
    "rubric={points:4}\n",
    "\n",
    "The following code varies the `max_features` hyperparameter of `CountVectorizer` and makes a plot (with the x-axis on a log scale) that shows train/cross-validation scores vs. `max_features`. It also prints the results. Based on the plot/output, what value of `max_features` seems best? Briefly explain.\n",
    "\n",
    "Note: the code may take a minute or two to run. You can uncomment the `print` statement if you want to see it show the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "S0akpMpethI3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "max_features = [10, 100, 1000, 10_000, 100_000]\n",
    "\n",
    "for mf in max_features:\n",
    "    #     print(mf)\n",
    "    pipe = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\", max_features=mf),\n",
    "        LogisticRegression(max_iter=1000),\n",
    "    )\n",
    "    cv_results = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    "    train_scores.append(cv_results[\"train_score\"].mean())\n",
    "    cv_scores.append(cv_results[\"test_score\"].mean())\n",
    "\n",
    "plt.semilogx(max_features, train_scores, label=\"train\")\n",
    "plt.semilogx(max_features, cv_scores, label=\"valid\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMxpaVG5thI4"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSmZiuXFthI4"
   },
   "source": [
    "#### 3(b)\n",
    "rubric={points:4}\n",
    "\n",
    "The following code varies the `C` hyperparameter of `LogisticRegression` and makes a plot (with the x-axis on a log scale) that shows train/cross-validation scores vs. `C`. Based on the plot, what value of `C` seems best?\n",
    "\n",
    "Note: the code may take a minute or two to run. You can uncomment the `print` statement if you want to see it show the progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_uBroJethI5"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUNFiyeDthI5"
   },
   "source": [
    "#### 3(c)\n",
    "rubric={points:12}\n",
    "\n",
    "- Using `GridSearchCV`, jointly optimize `max_features` and `C` across all the combinations of values we tried above. \n",
    "  - Note: the code might be a bit slow here. \n",
    "  - Setting `n_jobs=-1` should speed it up if you have a multi-core processor.\n",
    "  - You can reduce the number of folds (e.g. `cv=2`) to speed it up if necessary.\n",
    "- What are the best values of `max_features` and `C` according to your grid search?\n",
    "- Do these best values agree with what you found in parts (a) and (b)?\n",
    "- Generally speaking, _should_ these values agree with what you found in parts (a) and (b)? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prmts={\n",
    "    'logisticregression__C': [0.001,0.01,0.1,1,10,10,100],\n",
    "    'countvectorizer__max_features':[10,100,1000,10000,100000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\"),\n",
    "        LogisticRegression(max_iter=1000),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe,prmts,cv=5,verbose=3,n_jobs=-1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;countvectorizer__max_features&#x27;: [10, 100, 1000, 10000,\n",
       "                                                           100000],\n",
       "                         &#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 10,\n",
       "                                                   100]},\n",
       "             return_train_score=True, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;countvectorizer__max_features&#x27;: [10, 100, 1000, 10000,\n",
       "                                                           100000],\n",
       "                         &#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 10,\n",
       "                                                   100]},\n",
       "             return_train_score=True, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [10, 100, 1000, 10000,\n",
       "                                                           100000],\n",
       "                         'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 10,\n",
       "                                                   100]},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;countvectorizer__max_features&#x27;: [10, 100, 1000, 10000,\n",
       "                                                           100000],\n",
       "                         &#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 10,\n",
       "                                                   100]},\n",
       "             return_train_score=True, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                                        CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;countvectorizer__max_features&#x27;: [10, 100, 1000, 10000,\n",
       "                                                           100000],\n",
       "                         &#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 10,\n",
       "                                                   100]},\n",
       "             return_train_score=True, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [10, 100, 1000, 10000,\n",
       "                                                           100000],\n",
       "                         'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 10,\n",
       "                                                   100]},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.822669</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.779652</td>\n",
       "      <td>0.766438</td>\n",
       "      <td>0.758366</td>\n",
       "      <td>0.726487</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.74695</td>\n",
       "      <td>0.808625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.960513</td>\n",
       "      <td>7.320526</td>\n",
       "      <td>12.05238</td>\n",
       "      <td>3.177739</td>\n",
       "      <td>3.336459</td>\n",
       "      <td>4.510083</td>\n",
       "      <td>5.740854</td>\n",
       "      <td>9.373262</td>\n",
       "      <td>10.236762</td>\n",
       "      <td>11.344918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.026988</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>0.018981</td>\n",
       "      <td>0.026375</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.019679</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.027914</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02894</td>\n",
       "      <td>0.81373</td>\n",
       "      <td>1.41575</td>\n",
       "      <td>0.499594</td>\n",
       "      <td>0.659841</td>\n",
       "      <td>0.555016</td>\n",
       "      <td>0.73065</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>1.099073</td>\n",
       "      <td>0.705663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.150088</td>\n",
       "      <td>0.151237</td>\n",
       "      <td>0.147846</td>\n",
       "      <td>0.138596</td>\n",
       "      <td>0.150395</td>\n",
       "      <td>0.144926</td>\n",
       "      <td>0.146048</td>\n",
       "      <td>0.147944</td>\n",
       "      <td>0.144107</td>\n",
       "      <td>0.146686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780217</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.41227</td>\n",
       "      <td>0.641602</td>\n",
       "      <td>0.580815</td>\n",
       "      <td>0.902719</td>\n",
       "      <td>0.722355</td>\n",
       "      <td>0.525694</td>\n",
       "      <td>0.375609</td>\n",
       "      <td>0.2087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.00551</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.01941</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.175712</td>\n",
       "      <td>0.166453</td>\n",
       "      <td>0.122739</td>\n",
       "      <td>0.149357</td>\n",
       "      <td>0.347436</td>\n",
       "      <td>0.15865</td>\n",
       "      <td>0.14945</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.018932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 10, 'logisti...</td>\n",
       "      <td>{'countvectorizer__max_features': 100, 'logist...</td>\n",
       "      <td>{'countvectorizer__max_features': 100, 'logist...</td>\n",
       "      <td>{'countvectorizer__max_features': 100, 'logist...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'countvectorizer__max_features': 10000, 'logi...</td>\n",
       "      <td>{'countvectorizer__max_features': 10000, 'logi...</td>\n",
       "      <td>{'countvectorizer__max_features': 10000, 'logi...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "      <td>{'countvectorizer__max_features': 100000, 'log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.74012</td>\n",
       "      <td>0.755497</td>\n",
       "      <td>0.764724</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>0.751807</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.837767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>0.862679</td>\n",
       "      <td>0.760572</td>\n",
       "      <td>0.859911</td>\n",
       "      <td>0.894049</td>\n",
       "      <td>0.899123</td>\n",
       "      <td>0.889436</td>\n",
       "      <td>0.889436</td>\n",
       "      <td>0.873135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.737813</td>\n",
       "      <td>0.750423</td>\n",
       "      <td>0.77149</td>\n",
       "      <td>0.769952</td>\n",
       "      <td>0.769952</td>\n",
       "      <td>0.769952</td>\n",
       "      <td>0.769952</td>\n",
       "      <td>0.747501</td>\n",
       "      <td>0.820237</td>\n",
       "      <td>0.838382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884822</td>\n",
       "      <td>0.884822</td>\n",
       "      <td>0.866369</td>\n",
       "      <td>0.757804</td>\n",
       "      <td>0.856528</td>\n",
       "      <td>0.891588</td>\n",
       "      <td>0.899739</td>\n",
       "      <td>0.891588</td>\n",
       "      <td>0.891588</td>\n",
       "      <td>0.879902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.736276</td>\n",
       "      <td>0.744887</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>0.762725</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>0.75073</td>\n",
       "      <td>0.81424</td>\n",
       "      <td>0.836229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884207</td>\n",
       "      <td>0.884207</td>\n",
       "      <td>0.867907</td>\n",
       "      <td>0.761648</td>\n",
       "      <td>0.858988</td>\n",
       "      <td>0.895279</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>0.88636</td>\n",
       "      <td>0.88636</td>\n",
       "      <td>0.873443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.737044</td>\n",
       "      <td>0.744579</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.765339</td>\n",
       "      <td>0.765339</td>\n",
       "      <td>0.765339</td>\n",
       "      <td>0.765339</td>\n",
       "      <td>0.746732</td>\n",
       "      <td>0.814086</td>\n",
       "      <td>0.838382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883746</td>\n",
       "      <td>0.883746</td>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.757804</td>\n",
       "      <td>0.858988</td>\n",
       "      <td>0.894203</td>\n",
       "      <td>0.898201</td>\n",
       "      <td>0.889589</td>\n",
       "      <td>0.889589</td>\n",
       "      <td>0.876057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.737312</td>\n",
       "      <td>0.751769</td>\n",
       "      <td>0.769148</td>\n",
       "      <td>0.769763</td>\n",
       "      <td>0.769763</td>\n",
       "      <td>0.769763</td>\n",
       "      <td>0.769763</td>\n",
       "      <td>0.74777</td>\n",
       "      <td>0.813134</td>\n",
       "      <td>0.831898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885727</td>\n",
       "      <td>0.885727</td>\n",
       "      <td>0.864042</td>\n",
       "      <td>0.756383</td>\n",
       "      <td>0.85343</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.896032</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.870348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.737713</td>\n",
       "      <td>0.749431</td>\n",
       "      <td>0.766747</td>\n",
       "      <td>0.766593</td>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.766562</td>\n",
       "      <td>0.748908</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.836532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88485</td>\n",
       "      <td>0.88485</td>\n",
       "      <td>0.864458</td>\n",
       "      <td>0.758842</td>\n",
       "      <td>0.857569</td>\n",
       "      <td>0.893277</td>\n",
       "      <td>0.89789</td>\n",
       "      <td>0.888171</td>\n",
       "      <td>0.888171</td>\n",
       "      <td>0.874577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.00273</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.003219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.737726</td>\n",
       "      <td>0.751644</td>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.748299</td>\n",
       "      <td>0.817077</td>\n",
       "      <td>0.836761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97701</td>\n",
       "      <td>0.97701</td>\n",
       "      <td>0.987659</td>\n",
       "      <td>0.759871</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.919957</td>\n",
       "      <td>0.966014</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.998232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.738265</td>\n",
       "      <td>0.751336</td>\n",
       "      <td>0.768406</td>\n",
       "      <td>0.770482</td>\n",
       "      <td>0.770482</td>\n",
       "      <td>0.770482</td>\n",
       "      <td>0.770482</td>\n",
       "      <td>0.749375</td>\n",
       "      <td>0.81677</td>\n",
       "      <td>0.837684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97774</td>\n",
       "      <td>0.97774</td>\n",
       "      <td>0.98789</td>\n",
       "      <td>0.760448</td>\n",
       "      <td>0.865019</td>\n",
       "      <td>0.91815</td>\n",
       "      <td>0.968859</td>\n",
       "      <td>0.993426</td>\n",
       "      <td>0.993426</td>\n",
       "      <td>0.998808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.737842</td>\n",
       "      <td>0.748414</td>\n",
       "      <td>0.765715</td>\n",
       "      <td>0.766022</td>\n",
       "      <td>0.766022</td>\n",
       "      <td>0.766022</td>\n",
       "      <td>0.766022</td>\n",
       "      <td>0.74876</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>0.837915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97751</td>\n",
       "      <td>0.97751</td>\n",
       "      <td>0.987621</td>\n",
       "      <td>0.758948</td>\n",
       "      <td>0.864096</td>\n",
       "      <td>0.919496</td>\n",
       "      <td>0.965976</td>\n",
       "      <td>0.994195</td>\n",
       "      <td>0.994195</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.737919</td>\n",
       "      <td>0.748491</td>\n",
       "      <td>0.767445</td>\n",
       "      <td>0.76806</td>\n",
       "      <td>0.76806</td>\n",
       "      <td>0.76806</td>\n",
       "      <td>0.76806</td>\n",
       "      <td>0.75049</td>\n",
       "      <td>0.818154</td>\n",
       "      <td>0.83803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977125</td>\n",
       "      <td>0.977125</td>\n",
       "      <td>0.987352</td>\n",
       "      <td>0.760794</td>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.918534</td>\n",
       "      <td>0.968552</td>\n",
       "      <td>0.994041</td>\n",
       "      <td>0.994041</td>\n",
       "      <td>0.998808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.73839</td>\n",
       "      <td>0.750423</td>\n",
       "      <td>0.768722</td>\n",
       "      <td>0.766877</td>\n",
       "      <td>0.766877</td>\n",
       "      <td>0.766877</td>\n",
       "      <td>0.766877</td>\n",
       "      <td>0.749885</td>\n",
       "      <td>0.818046</td>\n",
       "      <td>0.83819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977664</td>\n",
       "      <td>0.977664</td>\n",
       "      <td>0.987736</td>\n",
       "      <td>0.76061</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>0.919845</td>\n",
       "      <td>0.965823</td>\n",
       "      <td>0.993695</td>\n",
       "      <td>0.993695</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.738028</td>\n",
       "      <td>0.750062</td>\n",
       "      <td>0.767623</td>\n",
       "      <td>0.767854</td>\n",
       "      <td>0.767854</td>\n",
       "      <td>0.767854</td>\n",
       "      <td>0.767854</td>\n",
       "      <td>0.749362</td>\n",
       "      <td>0.817709</td>\n",
       "      <td>0.837716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97741</td>\n",
       "      <td>0.97741</td>\n",
       "      <td>0.987651</td>\n",
       "      <td>0.760134</td>\n",
       "      <td>0.864904</td>\n",
       "      <td>0.919196</td>\n",
       "      <td>0.967045</td>\n",
       "      <td>0.993733</td>\n",
       "      <td>0.993733</td>\n",
       "      <td>0.99877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    0   \\\n",
       "mean_fit_time                                                                 0.805833   \n",
       "std_fit_time                                                                  0.026988   \n",
       "mean_score_time                                                               0.150088   \n",
       "std_score_time                                                                0.008659   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                      0.001   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                              0.74012   \n",
       "split1_test_score                                                             0.737813   \n",
       "split2_test_score                                                             0.736276   \n",
       "split3_test_score                                                             0.737044   \n",
       "split4_test_score                                                             0.737312   \n",
       "mean_test_score                                                               0.737713   \n",
       "std_test_score                                                                0.001302   \n",
       "rank_test_score                                                                     35   \n",
       "split0_train_score                                                            0.737726   \n",
       "split1_train_score                                                            0.738265   \n",
       "split2_train_score                                                            0.737842   \n",
       "split3_train_score                                                            0.737919   \n",
       "split4_train_score                                                             0.73839   \n",
       "mean_train_score                                                              0.738028   \n",
       "std_train_score                                                               0.000255   \n",
       "\n",
       "                                                                                    1   \\\n",
       "mean_fit_time                                                                 0.822669   \n",
       "std_fit_time                                                                  0.019957   \n",
       "mean_score_time                                                               0.151237   \n",
       "std_score_time                                                                 0.00551   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                       0.01   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                             0.755497   \n",
       "split1_test_score                                                             0.750423   \n",
       "split2_test_score                                                             0.744887   \n",
       "split3_test_score                                                             0.744579   \n",
       "split4_test_score                                                             0.751769   \n",
       "mean_test_score                                                               0.749431   \n",
       "std_test_score                                                                0.004182   \n",
       "rank_test_score                                                                     33   \n",
       "split0_train_score                                                            0.751644   \n",
       "split1_train_score                                                            0.751336   \n",
       "split2_train_score                                                            0.748414   \n",
       "split3_train_score                                                            0.748491   \n",
       "split4_train_score                                                            0.750423   \n",
       "mean_train_score                                                              0.750062   \n",
       "std_train_score                                                               0.001374   \n",
       "\n",
       "                                                                                    2   \\\n",
       "mean_fit_time                                                                 0.817985   \n",
       "std_fit_time                                                                  0.018981   \n",
       "mean_score_time                                                               0.147846   \n",
       "std_score_time                                                                0.006805   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                        0.1   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                             0.764724   \n",
       "split1_test_score                                                              0.77149   \n",
       "split2_test_score                                                             0.762571   \n",
       "split3_test_score                                                               0.7658   \n",
       "split4_test_score                                                             0.769148   \n",
       "mean_test_score                                                               0.766747   \n",
       "std_test_score                                                                0.003184   \n",
       "rank_test_score                                                                     25   \n",
       "split0_train_score                                                            0.767829   \n",
       "split1_train_score                                                            0.768406   \n",
       "split2_train_score                                                            0.765715   \n",
       "split3_train_score                                                            0.767445   \n",
       "split4_train_score                                                            0.768722   \n",
       "mean_train_score                                                              0.767623   \n",
       "std_train_score                                                               0.001052   \n",
       "\n",
       "                                                                                    3   \\\n",
       "mean_fit_time                                                                 0.779652   \n",
       "std_fit_time                                                                  0.026375   \n",
       "mean_score_time                                                               0.138596   \n",
       "std_score_time                                                                0.002304   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                          1   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                             0.765185   \n",
       "split1_test_score                                                             0.769952   \n",
       "split2_test_score                                                             0.762725   \n",
       "split3_test_score                                                             0.765339   \n",
       "split4_test_score                                                             0.769763   \n",
       "mean_test_score                                                               0.766593   \n",
       "std_test_score                                                                0.002823   \n",
       "rank_test_score                                                                     26   \n",
       "split0_train_score                                                            0.767829   \n",
       "split1_train_score                                                            0.770482   \n",
       "split2_train_score                                                            0.766022   \n",
       "split3_train_score                                                             0.76806   \n",
       "split4_train_score                                                            0.766877   \n",
       "mean_train_score                                                              0.767854   \n",
       "std_train_score                                                               0.001501   \n",
       "\n",
       "                                                                                    4   \\\n",
       "mean_fit_time                                                                 0.766438   \n",
       "std_fit_time                                                                  0.030878   \n",
       "mean_score_time                                                               0.150395   \n",
       "std_score_time                                                                0.006883   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                         10   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                             0.765185   \n",
       "split1_test_score                                                             0.769952   \n",
       "split2_test_score                                                             0.762571   \n",
       "split3_test_score                                                             0.765339   \n",
       "split4_test_score                                                             0.769763   \n",
       "mean_test_score                                                               0.766562   \n",
       "std_test_score                                                                0.002866   \n",
       "rank_test_score                                                                     27   \n",
       "split0_train_score                                                            0.767829   \n",
       "split1_train_score                                                            0.770482   \n",
       "split2_train_score                                                            0.766022   \n",
       "split3_train_score                                                             0.76806   \n",
       "split4_train_score                                                            0.766877   \n",
       "mean_train_score                                                              0.767854   \n",
       "std_train_score                                                               0.001501   \n",
       "\n",
       "                                                                                    5   \\\n",
       "mean_fit_time                                                                 0.758366   \n",
       "std_fit_time                                                                  0.013712   \n",
       "mean_score_time                                                               0.144926   \n",
       "std_score_time                                                                0.005515   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                         10   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                             0.765185   \n",
       "split1_test_score                                                             0.769952   \n",
       "split2_test_score                                                             0.762571   \n",
       "split3_test_score                                                             0.765339   \n",
       "split4_test_score                                                             0.769763   \n",
       "mean_test_score                                                               0.766562   \n",
       "std_test_score                                                                0.002866   \n",
       "rank_test_score                                                                     27   \n",
       "split0_train_score                                                            0.767829   \n",
       "split1_train_score                                                            0.770482   \n",
       "split2_train_score                                                            0.766022   \n",
       "split3_train_score                                                             0.76806   \n",
       "split4_train_score                                                            0.766877   \n",
       "mean_train_score                                                              0.767854   \n",
       "std_train_score                                                               0.001501   \n",
       "\n",
       "                                                                                    6   \\\n",
       "mean_fit_time                                                                 0.726487   \n",
       "std_fit_time                                                                  0.019679   \n",
       "mean_score_time                                                               0.146048   \n",
       "std_score_time                                                                 0.01941   \n",
       "param_countvectorizer__max_features                                                 10   \n",
       "param_logisticregression__C                                                        100   \n",
       "params                               {'countvectorizer__max_features': 10, 'logisti...   \n",
       "split0_test_score                                                             0.765185   \n",
       "split1_test_score                                                             0.769952   \n",
       "split2_test_score                                                             0.762571   \n",
       "split3_test_score                                                             0.765339   \n",
       "split4_test_score                                                             0.769763   \n",
       "mean_test_score                                                               0.766562   \n",
       "std_test_score                                                                0.002866   \n",
       "rank_test_score                                                                     27   \n",
       "split0_train_score                                                            0.767829   \n",
       "split1_train_score                                                            0.770482   \n",
       "split2_train_score                                                            0.766022   \n",
       "split3_train_score                                                             0.76806   \n",
       "split4_train_score                                                            0.766877   \n",
       "mean_train_score                                                              0.767854   \n",
       "std_train_score                                                               0.001501   \n",
       "\n",
       "                                                                                    7   \\\n",
       "mean_fit_time                                                                 0.715976   \n",
       "std_fit_time                                                                  0.025746   \n",
       "mean_score_time                                                               0.147944   \n",
       "std_score_time                                                                0.011611   \n",
       "param_countvectorizer__max_features                                                100   \n",
       "param_logisticregression__C                                                      0.001   \n",
       "params                               {'countvectorizer__max_features': 100, 'logist...   \n",
       "split0_test_score                                                             0.751807   \n",
       "split1_test_score                                                             0.747501   \n",
       "split2_test_score                                                              0.75073   \n",
       "split3_test_score                                                             0.746732   \n",
       "split4_test_score                                                              0.74777   \n",
       "mean_test_score                                                               0.748908   \n",
       "std_test_score                                                                0.001987   \n",
       "rank_test_score                                                                     34   \n",
       "split0_train_score                                                            0.748299   \n",
       "split1_train_score                                                            0.749375   \n",
       "split2_train_score                                                             0.74876   \n",
       "split3_train_score                                                             0.75049   \n",
       "split4_train_score                                                            0.749885   \n",
       "mean_train_score                                                              0.749362   \n",
       "std_train_score                                                                0.00078   \n",
       "\n",
       "                                                                                    8   \\\n",
       "mean_fit_time                                                                  0.74695   \n",
       "std_fit_time                                                                  0.014094   \n",
       "mean_score_time                                                               0.144107   \n",
       "std_score_time                                                                0.003547   \n",
       "param_countvectorizer__max_features                                                100   \n",
       "param_logisticregression__C                                                       0.01   \n",
       "params                               {'countvectorizer__max_features': 100, 'logist...   \n",
       "split0_test_score                                                             0.818084   \n",
       "split1_test_score                                                             0.820237   \n",
       "split2_test_score                                                              0.81424   \n",
       "split3_test_score                                                             0.814086   \n",
       "split4_test_score                                                             0.813134   \n",
       "mean_test_score                                                               0.815956   \n",
       "std_test_score                                                                 0.00273   \n",
       "rank_test_score                                                                     24   \n",
       "split0_train_score                                                            0.817077   \n",
       "split1_train_score                                                             0.81677   \n",
       "split2_train_score                                                              0.8185   \n",
       "split3_train_score                                                            0.818154   \n",
       "split4_train_score                                                            0.818046   \n",
       "mean_train_score                                                              0.817709   \n",
       "std_train_score                                                               0.000666   \n",
       "\n",
       "                                                                                    9   \\\n",
       "mean_fit_time                                                                 0.808625   \n",
       "std_fit_time                                                                  0.027914   \n",
       "mean_score_time                                                               0.146686   \n",
       "std_score_time                                                                0.010876   \n",
       "param_countvectorizer__max_features                                                100   \n",
       "param_logisticregression__C                                                        0.1   \n",
       "params                               {'countvectorizer__max_features': 100, 'logist...   \n",
       "split0_test_score                                                             0.837767   \n",
       "split1_test_score                                                             0.838382   \n",
       "split2_test_score                                                             0.836229   \n",
       "split3_test_score                                                             0.838382   \n",
       "split4_test_score                                                             0.831898   \n",
       "mean_test_score                                                               0.836532   \n",
       "std_test_score                                                                0.002447   \n",
       "rank_test_score                                                                     23   \n",
       "split0_train_score                                                            0.836761   \n",
       "split1_train_score                                                            0.837684   \n",
       "split2_train_score                                                            0.837915   \n",
       "split3_train_score                                                             0.83803   \n",
       "split4_train_score                                                             0.83819   \n",
       "mean_train_score                                                              0.837716   \n",
       "std_train_score                                                               0.000505   \n",
       "\n",
       "                                     ...  \\\n",
       "mean_fit_time                        ...   \n",
       "std_fit_time                         ...   \n",
       "mean_score_time                      ...   \n",
       "std_score_time                       ...   \n",
       "param_countvectorizer__max_features  ...   \n",
       "param_logisticregression__C          ...   \n",
       "params                               ...   \n",
       "split0_test_score                    ...   \n",
       "split1_test_score                    ...   \n",
       "split2_test_score                    ...   \n",
       "split3_test_score                    ...   \n",
       "split4_test_score                    ...   \n",
       "mean_test_score                      ...   \n",
       "std_test_score                       ...   \n",
       "rank_test_score                      ...   \n",
       "split0_train_score                   ...   \n",
       "split1_train_score                   ...   \n",
       "split2_train_score                   ...   \n",
       "split3_train_score                   ...   \n",
       "split4_train_score                   ...   \n",
       "mean_train_score                     ...   \n",
       "std_train_score                      ...   \n",
       "\n",
       "                                                                                    25  \\\n",
       "mean_fit_time                                                                 7.960513   \n",
       "std_fit_time                                                                   1.02894   \n",
       "mean_score_time                                                               0.780217   \n",
       "std_score_time                                                                0.217137   \n",
       "param_countvectorizer__max_features                                              10000   \n",
       "param_logisticregression__C                                                         10   \n",
       "params                               {'countvectorizer__max_features': 10000, 'logi...   \n",
       "split0_test_score                                                             0.885745   \n",
       "split1_test_score                                                             0.884822   \n",
       "split2_test_score                                                             0.884207   \n",
       "split3_test_score                                                             0.883746   \n",
       "split4_test_score                                                             0.885727   \n",
       "mean_test_score                                                                0.88485   \n",
       "std_test_score                                                                  0.0008   \n",
       "rank_test_score                                                                     12   \n",
       "split0_train_score                                                             0.97701   \n",
       "split1_train_score                                                             0.97774   \n",
       "split2_train_score                                                             0.97751   \n",
       "split3_train_score                                                            0.977125   \n",
       "split4_train_score                                                            0.977664   \n",
       "mean_train_score                                                               0.97741   \n",
       "std_train_score                                                               0.000292   \n",
       "\n",
       "                                                                                    26  \\\n",
       "mean_fit_time                                                                 7.320526   \n",
       "std_fit_time                                                                   0.81373   \n",
       "mean_score_time                                                                 0.3964   \n",
       "std_score_time                                                                0.175712   \n",
       "param_countvectorizer__max_features                                              10000   \n",
       "param_logisticregression__C                                                         10   \n",
       "params                               {'countvectorizer__max_features': 10000, 'logi...   \n",
       "split0_test_score                                                             0.885745   \n",
       "split1_test_score                                                             0.884822   \n",
       "split2_test_score                                                             0.884207   \n",
       "split3_test_score                                                             0.883746   \n",
       "split4_test_score                                                             0.885727   \n",
       "mean_test_score                                                                0.88485   \n",
       "std_test_score                                                                  0.0008   \n",
       "rank_test_score                                                                     12   \n",
       "split0_train_score                                                             0.97701   \n",
       "split1_train_score                                                             0.97774   \n",
       "split2_train_score                                                             0.97751   \n",
       "split3_train_score                                                            0.977125   \n",
       "split4_train_score                                                            0.977664   \n",
       "mean_train_score                                                               0.97741   \n",
       "std_train_score                                                               0.000292   \n",
       "\n",
       "                                                                                    27  \\\n",
       "mean_fit_time                                                                 12.05238   \n",
       "std_fit_time                                                                   1.41575   \n",
       "mean_score_time                                                                0.41227   \n",
       "std_score_time                                                                0.166453   \n",
       "param_countvectorizer__max_features                                              10000   \n",
       "param_logisticregression__C                                                        100   \n",
       "params                               {'countvectorizer__max_features': 10000, 'logi...   \n",
       "split0_test_score                                                             0.862679   \n",
       "split1_test_score                                                             0.866369   \n",
       "split2_test_score                                                             0.867907   \n",
       "split3_test_score                                                             0.861295   \n",
       "split4_test_score                                                             0.864042   \n",
       "mean_test_score                                                               0.864458   \n",
       "std_test_score                                                                0.002404   \n",
       "rank_test_score                                                                     15   \n",
       "split0_train_score                                                            0.987659   \n",
       "split1_train_score                                                             0.98789   \n",
       "split2_train_score                                                            0.987621   \n",
       "split3_train_score                                                            0.987352   \n",
       "split4_train_score                                                            0.987736   \n",
       "mean_train_score                                                              0.987651   \n",
       "std_train_score                                                               0.000176   \n",
       "\n",
       "                                                                                    28  \\\n",
       "mean_fit_time                                                                 3.177739   \n",
       "std_fit_time                                                                  0.499594   \n",
       "mean_score_time                                                               0.641602   \n",
       "std_score_time                                                                0.122739   \n",
       "param_countvectorizer__max_features                                             100000   \n",
       "param_logisticregression__C                                                      0.001   \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...   \n",
       "split0_test_score                                                             0.760572   \n",
       "split1_test_score                                                             0.757804   \n",
       "split2_test_score                                                             0.761648   \n",
       "split3_test_score                                                             0.757804   \n",
       "split4_test_score                                                             0.756383   \n",
       "mean_test_score                                                               0.758842   \n",
       "std_test_score                                                                0.001953   \n",
       "rank_test_score                                                                     30   \n",
       "split0_train_score                                                            0.759871   \n",
       "split1_train_score                                                            0.760448   \n",
       "split2_train_score                                                            0.758948   \n",
       "split3_train_score                                                            0.760794   \n",
       "split4_train_score                                                             0.76061   \n",
       "mean_train_score                                                              0.760134   \n",
       "std_train_score                                                               0.000669   \n",
       "\n",
       "                                                                                    29  \\\n",
       "mean_fit_time                                                                 3.336459   \n",
       "std_fit_time                                                                  0.659841   \n",
       "mean_score_time                                                               0.580815   \n",
       "std_score_time                                                                0.149357   \n",
       "param_countvectorizer__max_features                                             100000   \n",
       "param_logisticregression__C                                                       0.01   \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...   \n",
       "split0_test_score                                                             0.859911   \n",
       "split1_test_score                                                             0.856528   \n",
       "split2_test_score                                                             0.858988   \n",
       "split3_test_score                                                             0.858988   \n",
       "split4_test_score                                                              0.85343   \n",
       "mean_test_score                                                               0.857569   \n",
       "std_test_score                                                                0.002355   \n",
       "rank_test_score                                                                     16   \n",
       "split0_train_score                                                            0.864557   \n",
       "split1_train_score                                                            0.865019   \n",
       "split2_train_score                                                            0.864096   \n",
       "split3_train_score                                                            0.865442   \n",
       "split4_train_score                                                            0.865408   \n",
       "mean_train_score                                                              0.864904   \n",
       "std_train_score                                                               0.000516   \n",
       "\n",
       "                                                                                    30  \\\n",
       "mean_fit_time                                                                 4.510083   \n",
       "std_fit_time                                                                  0.555016   \n",
       "mean_score_time                                                               0.902719   \n",
       "std_score_time                                                                0.347436   \n",
       "param_countvectorizer__max_features                                             100000   \n",
       "param_logisticregression__C                                                        0.1   \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...   \n",
       "split0_test_score                                                             0.894049   \n",
       "split1_test_score                                                             0.891588   \n",
       "split2_test_score                                                             0.895279   \n",
       "split3_test_score                                                             0.894203   \n",
       "split4_test_score                                                             0.891264   \n",
       "mean_test_score                                                               0.893277   \n",
       "std_test_score                                                                0.001572   \n",
       "rank_test_score                                                                      4   \n",
       "split0_train_score                                                            0.919957   \n",
       "split1_train_score                                                             0.91815   \n",
       "split2_train_score                                                            0.919496   \n",
       "split3_train_score                                                            0.918534   \n",
       "split4_train_score                                                            0.919845   \n",
       "mean_train_score                                                              0.919196   \n",
       "std_train_score                                                               0.000724   \n",
       "\n",
       "                                                                                    31  \\\n",
       "mean_fit_time                                                                 5.740854   \n",
       "std_fit_time                                                                   0.73065   \n",
       "mean_score_time                                                               0.722355   \n",
       "std_score_time                                                                 0.15865   \n",
       "param_countvectorizer__max_features                                             100000   \n",
       "param_logisticregression__C                                                          1   \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...   \n",
       "split0_test_score                                                             0.899123   \n",
       "split1_test_score                                                             0.899739   \n",
       "split2_test_score                                                             0.896356   \n",
       "split3_test_score                                                             0.898201   \n",
       "split4_test_score                                                             0.896032   \n",
       "mean_test_score                                                                0.89789   \n",
       "std_test_score                                                                0.001473   \n",
       "rank_test_score                                                                      1   \n",
       "split0_train_score                                                            0.966014   \n",
       "split1_train_score                                                            0.968859   \n",
       "split2_train_score                                                            0.965976   \n",
       "split3_train_score                                                            0.968552   \n",
       "split4_train_score                                                            0.965823   \n",
       "mean_train_score                                                              0.967045   \n",
       "std_train_score                                                               0.001361   \n",
       "\n",
       "                                                                                    32  \\\n",
       "mean_fit_time                                                                 9.373262   \n",
       "std_fit_time                                                                    0.8726   \n",
       "mean_score_time                                                               0.525694   \n",
       "std_score_time                                                                 0.14945   \n",
       "param_countvectorizer__max_features                                             100000   \n",
       "param_logisticregression__C                                                         10   \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...   \n",
       "split0_test_score                                                             0.889436   \n",
       "split1_test_score                                                             0.891588   \n",
       "split2_test_score                                                              0.88636   \n",
       "split3_test_score                                                             0.889589   \n",
       "split4_test_score                                                             0.883882   \n",
       "mean_test_score                                                               0.888171   \n",
       "std_test_score                                                                0.002719   \n",
       "rank_test_score                                                                      5   \n",
       "split0_train_score                                                            0.993311   \n",
       "split1_train_score                                                            0.993426   \n",
       "split2_train_score                                                            0.994195   \n",
       "split3_train_score                                                            0.994041   \n",
       "split4_train_score                                                            0.993695   \n",
       "mean_train_score                                                              0.993733   \n",
       "std_train_score                                                               0.000341   \n",
       "\n",
       "                                                                                    33  \\\n",
       "mean_fit_time                                                                10.236762   \n",
       "std_fit_time                                                                  1.099073   \n",
       "mean_score_time                                                               0.375609   \n",
       "std_score_time                                                                0.090651   \n",
       "param_countvectorizer__max_features                                             100000   \n",
       "param_logisticregression__C                                                         10   \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...   \n",
       "split0_test_score                                                             0.889436   \n",
       "split1_test_score                                                             0.891588   \n",
       "split2_test_score                                                              0.88636   \n",
       "split3_test_score                                                             0.889589   \n",
       "split4_test_score                                                             0.883882   \n",
       "mean_test_score                                                               0.888171   \n",
       "std_test_score                                                                0.002719   \n",
       "rank_test_score                                                                      5   \n",
       "split0_train_score                                                            0.993311   \n",
       "split1_train_score                                                            0.993426   \n",
       "split2_train_score                                                            0.994195   \n",
       "split3_train_score                                                            0.994041   \n",
       "split4_train_score                                                            0.993695   \n",
       "mean_train_score                                                              0.993733   \n",
       "std_train_score                                                               0.000341   \n",
       "\n",
       "                                                                                    34  \n",
       "mean_fit_time                                                                11.344918  \n",
       "std_fit_time                                                                  0.705663  \n",
       "mean_score_time                                                                 0.2087  \n",
       "std_score_time                                                                0.018932  \n",
       "param_countvectorizer__max_features                                             100000  \n",
       "param_logisticregression__C                                                        100  \n",
       "params                               {'countvectorizer__max_features': 100000, 'log...  \n",
       "split0_test_score                                                             0.873135  \n",
       "split1_test_score                                                             0.879902  \n",
       "split2_test_score                                                             0.873443  \n",
       "split3_test_score                                                             0.876057  \n",
       "split4_test_score                                                             0.870348  \n",
       "mean_test_score                                                               0.874577  \n",
       "std_test_score                                                                0.003219  \n",
       "rank_test_score                                                                     14  \n",
       "split0_train_score                                                            0.998232  \n",
       "split1_train_score                                                            0.998808  \n",
       "split2_train_score                                                               0.999  \n",
       "split3_train_score                                                            0.998808  \n",
       "split4_train_score                                                               0.999  \n",
       "mean_train_score                                                               0.99877  \n",
       "std_train_score                                                               0.000283  \n",
       "\n",
       "[22 rows x 35 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((grid_search.cv_results_)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978900824847041"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 100000, 'logisticregression__C': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEAJO96NthI6"
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1dmvz4QthI6"
   },
   "source": [
    "#### 3(d)\n",
    "rubric={points:5}\n",
    "\n",
    "- Evaluate your final model on the test set. \n",
    "- How does your test accuracy compare to your validation accuracy? \n",
    "- If they are different: do you think this is because you \"overfitted on the validation set\", or simply random luck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\", max_features=100000),\n",
    "        LogisticRegression(C=1,max_iter=1000),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                 CountVectorizer(max_features=100000, stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(C=1, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                 CountVectorizer(max_features=100000, stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(C=1, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=100000, stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(max_features=100000, stop_words='english')),\n",
       "                ('logisticregression', LogisticRegression(C=1, max_iter=1000))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993356707879683"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6bY9M55thI6"
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oksxqIRSthI6"
   },
   "source": [
    "## Exercise 4: Very short answer questions\n",
    "rubric={points:10}\n",
    "\n",
    "Each question is worth 2 points. Max 2 sentences per answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l-xHNlKthI6"
   },
   "source": [
    "1. What is the problem with calling `fit_transform` on your test data with `CountVectorizer`? \n",
    "2. Why is it important to follow the Golden Rule? If you violate it, will that give you a worse classifier?\n",
    "3. If you could only access one of `predict` or `predict_proba`, which one would you choose? Briefly explain.\n",
    "4. What are two advantages of using sklearn `Pipeline`s? \n",
    "5. What are two advantages of `RandomizedSearchCV` over `GridSearchCV`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans:1 for testtin data it cause the problem, cause of we initiallly learn the fit mathod on train data and now we apply on test, here we try to learn test data, whuch is not appropriatre,we have to see resuut on test data not learn the test data.\n",
    "# ans:2\n",
    "# ans:3 predict_proba\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKP3xAVgthI7"
   },
   "source": [
    "<br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
